{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from example_reactiondiffusion import get_rd_data\n",
    "from sindy_utils import library_size\n",
    "from training import train_network\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data_, validation_data_, test_data = get_rd_data()\n",
    "\n",
    "# Function to convert data to tensors and move to GPU\n",
    "def convert_to_tensors(data_dict, device):\n",
    "    for key, value in data_dict.items():\n",
    "        if value is not None:\n",
    "            data_dict[key] = torch.tensor(value).float().to(device)\n",
    "    return data_dict\n",
    "\n",
    "# Specify the device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Convert training and validation data to tensors and move to GPU\n",
    "training_data = convert_to_tensors(training_data_, device)\n",
    "validation_data = convert_to_tensors(validation_data_, device)\n",
    "\n",
    "# If 'ddx' is required and should be set to None\n",
    "training_data['ddx'] = None\n",
    "validation_data['ddx'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up model and training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {}\n",
    "params['input_dim'] = training_data['y1'].numel()*training_data['y2'].numel()\n",
    "params['latent_dim'] = 2\n",
    "params['model_order'] = 1\n",
    "params['poly_order'] = 3\n",
    "params['include_sine'] = True\n",
    "params['library_dim'] = library_size(params['latent_dim'], params['poly_order'], params['include_sine'], True)\n",
    "\n",
    "# sequential thresholding parameters\n",
    "params['sequential_thresholding'] = True\n",
    "params['coefficient_threshold'] = 0.1\n",
    "params['threshold_frequency'] = 500\n",
    "params['coefficient_mask'] = np.ones((params['library_dim'], params['latent_dim']))\n",
    "params['coefficient_initialization'] = 'constant'\n",
    "\n",
    "# loss function weighting\n",
    "params['loss_weight_decoder'] = 1.0\n",
    "params['loss_weight_sindy_z'] = 0.01\n",
    "params['loss_weight_sindy_x'] = 0.5\n",
    "params['loss_weight_sindy_regularization'] = 0.1\n",
    "\n",
    "params['activation'] = 'sigmoid'\n",
    "params['widths'] = [256]\n",
    "\n",
    "# training parameters\n",
    "params['epoch_size'] = training_data['t'].numel()\n",
    "params['batch_size'] = 1000\n",
    "params['learning_rate'] = 1e-3\n",
    "\n",
    "params['data_path'] = os.getcwd() + '/'\n",
    "params['print_progress'] = True\n",
    "params['print_frequency'] = 100\n",
    "\n",
    "# training time cutoffs\n",
    "params['max_epochs'] = 3001\n",
    "params['refinement_epochs'] = 1001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run training experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT 0\n",
      "TRAINING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zhaox\\OneDrive - Delft University of Technology\\桌面\\Q4\\reproductory\\report\\repo_sindy-main\\torch_result\\rd\\../..\\training.py:224: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'x': torch.tensor(data['x'][idxs], dtype=torch.float32).to(device),\n",
      "c:\\Users\\zhaox\\OneDrive - Delft University of Technology\\桌面\\Q4\\reproductory\\report\\repo_sindy-main\\torch_result\\rd\\../..\\training.py:225: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'dx': torch.tensor(data['dx'][idxs], dtype=torch.float32).to(device)\n",
      "c:\\Users\\zhaox\\OneDrive - Delft University of Technology\\桌面\\Q4\\reproductory\\report\\repo_sindy-main\\torch_result\\rd\\../..\\training.py:232: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data_dict['coefficient_mask'] = torch.tensor(params['coefficient_mask'], dtype=torch.float32).to(device)\n",
      "c:\\Users\\zhaox\\OneDrive - Delft University of Technology\\桌面\\Q4\\reproductory\\report\\repo_sindy-main\\torch_result\\rd\\../..\\training.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_tensor = torch.tensor(val_data['x'], dtype=torch.float32).to(device)\n",
      "c:\\Users\\zhaox\\OneDrive - Delft University of Technology\\桌面\\Q4\\reproductory\\report\\repo_sindy-main\\torch_result\\rd\\../..\\training.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_data['dx'] = torch.tensor(val_data['dx'], dtype=torch.float32).to(device)\n",
      "c:\\Users\\zhaox\\OneDrive - Delft University of Technology\\桌面\\Q4\\reproductory\\report\\repo_sindy-main\\torch_result\\rd\\../..\\training.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sindy_model_terms = [torch.sum(torch.tensor(params['coefficient_mask'])).cpu().numpy()]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "   Training Losses:\n",
      "      Total Loss: 0.44815441966056824\n",
      "      decoder Loss: 0.17480897903442383\n",
      "      sindy_z Loss: 10.60834789276123\n",
      "      sindy_x Loss: 0.13522449135780334\n",
      "      sindy_regularization Loss: 0.9964969158172607\n",
      "   Validation Losses:\n",
      "      Total Loss: 0.4494081437587738\n",
      "      decoder Loss: 0.17471599578857422\n",
      "      sindy_z Loss: 10.736557006835938\n",
      "      sindy_x Loss: 0.1353537142276764\n",
      "      sindy_regularization Loss: 0.9964969158172607\n",
      "Decoder Loss Ratio: 1.103888, Decoder SINDy Loss Ratio: 1.037172\n",
      "Epoch 100\n",
      "   Training Losses:\n",
      "      Total Loss: 0.16695299744606018\n",
      "      decoder Loss: 0.05220843106508255\n",
      "      sindy_z Loss: 0.4230600893497467\n",
      "      sindy_x Loss: 0.04619520530104637\n",
      "      sindy_regularization Loss: 0.8741636276245117\n",
      "   Validation Losses:\n",
      "      Total Loss: 0.16941338777542114\n",
      "      decoder Loss: 0.05384118854999542\n",
      "      sindy_z Loss: 0.424608051776886\n",
      "      sindy_x Loss: 0.047819528728723526\n",
      "      sindy_regularization Loss: 0.8741636276245117\n",
      "Decoder Loss Ratio: 0.340179, Decoder SINDy Loss Ratio: 0.366426\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msave_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrd_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS_\u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#tf.reset_default_graph()\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m results_dict \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# df = df.append({**results_dict, **params}, ignore_index=True)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df, pd\u001b[38;5;241m.\u001b[39mDataFrame([{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresults_dict, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams}])], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\zhaox\\OneDrive - Delft University of Technology\\桌面\\Q4\\reproductory\\report\\repo_sindy-main\\torch_result\\rd\\../..\\training.py:45\u001b[0m, in \u001b[0;36mtrain_network\u001b[1;34m(training_data, val_data, params)\u001b[0m\n\u001b[0;32m     43\u001b[0m batch_idxs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(j \u001b[38;5;241m*\u001b[39m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m], (j \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m#print(\"batch_idxs\", batch_idxs)\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m train_dict \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midxs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_idxs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# print(\"train_dict\", train_dict['x'][0])\u001b[39;00m\n\u001b[0;32m     47\u001b[0m x_batch, dx_batch, ddx_batch \u001b[38;5;241m=\u001b[39m train_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m], train_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdx\u001b[39m\u001b[38;5;124m'\u001b[39m], train_dict\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mddx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\zhaox\\OneDrive - Delft University of Technology\\桌面\\Q4\\reproductory\\report\\repo_sindy-main\\torch_result\\rd\\../..\\training.py:224\u001b[0m, in \u001b[0;36mprepare_data\u001b[1;34m(data, params, device, idxs)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m idxs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    222\u001b[0m     idxs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    223\u001b[0m data_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43midxs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdx\u001b[39m\u001b[38;5;124m'\u001b[39m: torch\u001b[38;5;241m.\u001b[39mtensor(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdx\u001b[39m\u001b[38;5;124m'\u001b[39m][idxs], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    226\u001b[0m }\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# print(\"data_dict['x']\", data_dict['x'])\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# print(\"data['x']\", data['x'])\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_order\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_experiments = 10\n",
    "df = pd.DataFrame()\n",
    "for i in range(num_experiments):\n",
    "    print('EXPERIMENT %d' % i)\n",
    "\n",
    "    params['coefficient_mask'] = torch.ones((params['library_dim'], params['latent_dim'])).to(\"cuda:0\")\n",
    "\n",
    "    params['save_name'] = 'rd_' + datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S_%f\")\n",
    "\n",
    "    #tf.reset_default_graph()\n",
    "\n",
    "    results_dict = train_network(training_data, validation_data, params)\n",
    "    # df = df.append({**results_dict, **params}, ignore_index=True)\n",
    "    df = pd.concat([df, pd.DataFrame([{**results_dict, **params}])], ignore_index=True)\n",
    "\n",
    "df.to_pickle('experiment_results_' + datetime.datetime.now().strftime(\"%Y%m%d%H%M\") + '.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
